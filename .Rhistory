scale_fill_lancet() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Screening of relevant predictor variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
screening_plot
# variable selection
included_var_garson <- NN_screen_importance %>%
filter(rel_imp > NN_screen_importance %>%
filter(str_detect(variables , "R[123]")) %>%
# the max importance of the random-value variables
summarize(rel_imp = max(rel_imp)) %>%
unlist) %>%
select(variables) %>%
filter(!str_detect(variables , "R[123]")) %>%
unlist %>% unname
# no selection
included_var_all <- colnames(data_daily)[!colnames(data_daily) %in% columns_nonpredictor]
# =====================================
# create hyperparameter grid
# =====================================
hyper_grid <- expand.grid(
layers = c(1,2,3,4) ,
neurons = c(5,10,50,100,200) ,
epochs = c(25,50) ,
batch.size = c(3,5,10,20,100) ,
regularization = c(NA,1,2) , # 1 for L1 and 2 for L2
regularization_factor = 0.001 ,
garson_selection = c(NA,1) , # NA for no selection; 1 for selection using Garson importance
dropout_rate = c(0 , 0.1 , 0.2)
)
# =====================================
# grid search
# =====================================
# parallel computation
cpu.cores <- detectCores()
cl <- makeCluster(cpu.cores)
# clusterExport
# 在使用預設PSOCK cluster時，若想要讓所有的節點可以使用預先設定好的全域變數，必須以clusterExport將變數傳遞至所有節點，之後才能在各個節點中使用
clusterExport(
cl = cl ,
varlist = c("data_monthly" , "k_fold" , "included_var_all" , "included_var_garson" , "NN_define")
)
# clusterExport
# 在使用預設PSOCK cluster時，若想要讓所有的節點可以使用預先設定好的全域變數，必須以clusterExport將變數傳遞至所有節點，之後才能在各個節點中使用
clusterExport(
cl = cl ,
varlist = c("data_daily" , "k_fold" , "included_var_all" , "included_var_garson" , "NN_define")
)
# grid search function for "apply"
search_hyper_grid <- function(df){
# df is the hyperparameter (one row of "hyper_grid")
# load packages for the clusters
library(dplyr) ; library(tidyr) ;
library(keras)
library(Metrics)
# =====================================
# feature selection
# =====================================
if(is.na(df["garson_selection"])){
included_var <- included_var_all
}else if(df["garson_selection"] == 1){
included_var <- included_var_garson
}
# =====================================
# full training set
# =====================================
training.data <- data_daily %>%
drop_na()
# make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(one_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
# prediction
prediction_training <- training.data %>%
select(date , Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(NN , predictor_train)[,1])
# # clean environment
# rm(training.data , predictor_train , response_train , NN)
# =====================================
# cross validation
# =====================================
for(k in as.factor(1:k_fold)){
# data preparation: partition
training.data <- data_daily %>%
filter(CV != k) %>%
drop_na()
testing.data <- data_daily %>%
filter(CV == k) %>%
drop_na()
# data preparation: make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(all_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
predictor_test <- testing.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(all_of(included_var)) %>%
as.matrix()
response_test <- testing.data %>%
select(NO2) %>%
as.matrix()
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
# prediction
prediction_test <- testing.data %>%
select(date , Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(NN , predictor_test)[,1])
# prediction data.frame
if(as.character(k) == "1"){
prediction_CV <- prediction_test # <-
}else{ # append
prediction_CV <- bind_rows(prediction_CV , prediction_test)
}
# clean environment
rm(k , training.data , testing.data ,
predictor_train , predictor_test , response_train , response_test ,
prediction_test)
}
# =====================================
# evaluate
# =====================================
hyper_evaluation_i <- df %>%
as.list() %>% as_tibble() %>%
bind_cols(
prediction_training %>%
full_join(prediction_CV ,
by = c("Station_name" , "NO2" , "Type_of_station" , "CV" , "date") ,
suffix = c("" , "_CV")) %>%
# calculate the indices from the observed and predicted values
summarize(MSE_training = mse(NO2 , predicted) ,
MSE_CV = mse(NO2 , predicted_CV) ,
MAE_training = mae(NO2 , predicted) ,
MAE_CV = mae(NO2 , predicted_CV) ,
R2_training = cor(NO2 , predicted)^2 ,
R2_CV = cor(NO2 , predicted_CV)^2 )
)
# function return
return(hyper_evaluation_i)
}
hyper_grid %>%
slice(1:2)
# grid search
hyper_evaluation <- hyper_grid %>%
slice(1:2) %>%
pbapply(MARGIN = 1 , FUN = search_hyper_grid , cl = cl) %>%
bind_rows()
df <- slice(hyper_grid , 1)
df
# =====================================
# feature selection
# =====================================
if(is.na(df["garson_selection"])){
included_var <- included_var_all
}else if(df["garson_selection"] == 1){
included_var <- included_var_garson
}
# =====================================
# full training set
# =====================================
training.data <- data_daily %>%
drop_na()
# make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(one_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = TRUE)
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = TRUE)
training.data
library(dplyr) ; library(tidyr) ;
library(keras)
library(Metrics)
# =====================================
# feature selection
# =====================================
if(is.na(df["garson_selection"])){
included_var <- included_var_all
}else if(df["garson_selection"] == 1){
included_var <- included_var_garson
}
# =====================================
# full training set
# =====================================
training.data <- data_daily %>%
drop_na()
# make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(one_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
training.data
included_var
# make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(one_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = TRUE)
NN
ncol(predictor_train)
# define model
NN_define(df , n_var = ncol(predictor_train))
df
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = TRUE)
# grid search function for "apply"
search_hyper_grid <- function(df){
# df is the hyperparameter (one row of "hyper_grid")
# load packages for the clusters
library(dplyr) ; library(tidyr) ;
library(keras)
library(Metrics)
# =====================================
# feature selection
# =====================================
if(is.na(df["garson_selection"])){
included_var <- included_var_all
}else if(df["garson_selection"] == 1){
included_var <- included_var_garson
}
# =====================================
# full training set
# =====================================
training.data <- data_daily %>%
drop_na()
# make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(one_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
# prediction
prediction_training <- training.data %>%
select(date , Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(NN , predictor_train)[,1])
# # clean environment
# rm(training.data , predictor_train , response_train , NN)
# =====================================
# cross validation
# =====================================
for(k in as.factor(1:k_fold)){
# data preparation: partition
training.data <- data_daily %>%
filter(CV != k) %>%
drop_na()
testing.data <- data_daily %>%
filter(CV == k) %>%
drop_na()
# data preparation: make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(all_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
predictor_test <- testing.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(all_of(included_var)) %>%
as.matrix()
response_test <- testing.data %>%
select(NO2) %>%
as.matrix()
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
# prediction
prediction_test <- testing.data %>%
select(date , Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(NN , predictor_test)[,1])
# prediction data.frame
if(as.character(k) == "1"){
prediction_CV <- prediction_test # <-
}else{ # append
prediction_CV <- bind_rows(prediction_CV , prediction_test)
}
# clean environment
rm(k , training.data , testing.data ,
predictor_train , predictor_test , response_train , response_test ,
prediction_test)
}
# =====================================
# evaluate
# =====================================
hyper_evaluation_i <- df %>%
as.list() %>% as_tibble() %>%
bind_cols(
prediction_training %>%
full_join(prediction_CV ,
by = c("Station_name" , "NO2" , "Type_of_station" , "CV" , "date") ,
suffix = c("" , "_CV")) %>%
# calculate the indices from the observed and predicted values
summarize(MSE_training = mse(NO2 , predicted) ,
MSE_CV = mse(NO2 , predicted_CV) ,
MAE_training = mae(NO2 , predicted) ,
MAE_CV = mae(NO2 , predicted_CV) ,
R2_training = cor(NO2 , predicted)^2 ,
R2_CV = cor(NO2 , predicted_CV)^2 )
)
# function return
return(hyper_evaluation_i)
}
df
search_hyper_grid(df)
# =====================================
# full training set
# =====================================
training.data <- data_daily %>%
drop_na()
# make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(one_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
rm(NN)
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
df
str(df)
df["epochs"]
df["epochs"] %>% class
df$epochs
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df$epochs ,
batch_size = df$batch.size ,
validation_split = 0.2 ,
verbose = FALSE)
hyper_grid[1,]
hyper_grid[1,] %>% as.list()
hyper_grid[1,] %>% as.matrix()
df <- hyper_grid[1,] %>% as.matrix()
df
df["epochs"]
df["layers"]
df$layers
# =====================================
# feature selection
# =====================================
if(is.na(df["garson_selection"])){
included_var <- included_var_all
}else if(df["garson_selection"] == 1){
included_var <- included_var_garson
}
# =====================================
# full training set
# =====================================
training.data <- data_daily %>%
drop_na()
# make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(one_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
# define model
NN_define(df , n_var = ncol(predictor_train))
df <- hyper_grid %>% slice(1) %>% unlist
df
# =====================================
# feature selection
# =====================================
if(is.na(df["garson_selection"])){
included_var <- included_var_all
}else if(df["garson_selection"] == 1){
included_var <- included_var_garson
}
# =====================================
# full training set
# =====================================
training.data <- data_daily %>%
drop_na()
# make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(one_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
# define model
NN_define(df , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = df["epochs"] ,
batch_size = df["batch.size"] ,
validation_split = 0.2 ,
verbose = TRUE)
training.data %>%
select(date , Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(NN , predictor_train)[,1])

labs(x = "Variables" , y = "Variable importance" ,
title = "Screening of relevant predictor variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
screen_plot
# variable selection
included_var_garson <- NN_screen_importance %>%
filter(rel_imp > NN_screen_importance %>%
filter(str_detect(variables , "R[123]")) %>%
# the max importance of the random-value variables
summarize(rel_imp = max(rel_imp)) %>%
unlist) %>%
select(variables) %>%
filter(!str_detect(variables , "R[123]")) %>%
unlist %>% unname
NN_screen_importance
NN_screen_importance %>%
filter(variables %in% included_var_garson)
NN_screen_importance %>%
filter(variables %in% included_var_garson) %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)]))
NN_screen_importance %>%
filter(variables %in% included_var_garson) %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)])) %>%
# visualization
ggplot(aes(x = variables , y = rel_imp)) +
geom_bar(stat = "identity") +
coord_flip() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Screening of relevant predictor variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
NN_screen_importance %>%
filter(variables %in% included_var_garson) %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)])) %>%
# visualization
ggplot(aes(x = variables , y = rel_imp)) +
geom_bar(stat = "identity") +
coord_flip() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Included variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
sprintf("%s/importance-included_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product)
# =====================================
# visualization
# =====================================
out_dirpath_plots <- sprintf("3_results/output-graph/model_monthly/%s" , model_abbr)
sprintf("%s/importance-included_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product)
save_plot(
sprintf("%s/importance-included_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product) ,
plot = last_plot() ,
base_width = 5 , base_height = 6
)
save_plot(
sprintf("%s/importance-screening_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product) ,
plot = screen_plot ,
base_width = 5 , base_height = 8
)
SAT_product <- c("OMI" , "TROPOMI")[2]
# subset data: satellite-product
if(SAT_product == "OMI"){
# for the OMI model: exclude TROPOMI and meteorological variables at 12H
data_monthly <- data_monthly_raw %>%
select(-TROPOMI_NO2 , -ends_with("_12H"))
}else if(SAT_product == "TROPOMI"){
# for the TROPOMI model: exclude OMI and meteorological variables at 15H
data_monthly <- data_monthly_raw %>%
select(-OMI_NO2 , -ends_with("_15H"))
}
# //////////////////////////////////////////////////////////////////////////
# model development
# //////////////////////////////////////////////////////////////////////////
# =====================================
# modularized NN model definition
# =====================================
source("2_scripts/utils_define-NN.R")
# =====================================
# feature selection
# =====================================
# single-hidden-layer neural network for screening
set.seed(20210727)
NN_screen <- nnet(
x = data_monthly %>%
drop_na() %>%
select(-all_of(columns_nonpredictor)) %>%
# random-value variables
mutate(R1 = runif(n()) ,
R2 = runif(n()) ,
R3 = runif(n()) ) ,
y = data_monthly %>%
drop_na() %>%
select(NO2) ,
size = 20 , linout = TRUE , MaxNWts = 1e4
)
# variables importance using Garson's algorithm
NN_screen_importance <- NeuralNetTools::garson(NN_screen , bar_plot = FALSE) %>%
tibble(variables = row.names(.))
screen_plot <- NN_screen_importance %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)])) %>%
# random
mutate(class = ifelse(str_detect(variables , "R[123]") , "Random" , "Predictor variables")) %>%
# visualization
ggplot(aes(x = variables , y = rel_imp , fill = class)) +
geom_bar(stat = "identity") +
coord_flip() +
scale_fill_lancet() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Screening of relevant predictor variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
# variable selection
included_var_garson <- NN_screen_importance %>%
filter(rel_imp > NN_screen_importance %>%
filter(str_detect(variables , "R[123]")) %>%
# the max importance of the random-value variables
summarize(rel_imp = max(rel_imp)) %>%
unlist) %>%
select(variables) %>%
filter(!str_detect(variables , "R[123]")) %>%
unlist %>% unname
out_dirpath_plots
# variable importance screening
screen_plot
save_plot(
sprintf("%s/importance-screening_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product) ,
plot = screen_plot ,
base_width = 5 , base_height = 8
)
NN_screen_importance %>%
filter(variables %in% included_var_garson) %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)])) %>%
# visualization
ggplot(aes(x = variables , y = rel_imp)) +
geom_bar(stat = "identity") +
coord_flip() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Included variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
save_plot(
sprintf("%s/importance-included_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product) ,
plot = last_plot() ,
base_width = 5 , base_height = 6
)
source("2_scripts/utils_model-eval.R")
# =====================================
# load datasets
# =====================================
# training data
data_daily_raw <- read_csv("1_data/processed/cleaned/extracted/daily_scaled.csv")
# cross validation
{
in_filepath_CV <- list.files("1_data/processed/cleaned/extracted/" , "CV.shp$" , full.names = TRUE)
sites_CV <- st_read(in_filepath_CV) %>%
rename(Station_name = Station)
k_fold <- in_filepath_CV %>%
str_extract("\\d+-fold") %>% str_extract("\\d+") %>%
as.integer()
}
# implement the CV design in the training data
data_daily_raw <- data_daily_raw %>%
inner_join(sites_CV , by = "Station_name") %>%
select(-geometry)
# DNN hyperparameters
# of the MONTHLY model
hyper_evaluation <- read_csv(
"3_results/output-data/model_monthly/NN_grid-search/hyper_evaluation.csv",
col_types = cols(layers = col_integer(),
neurons = col_integer(), epochs = col_integer(),
batch.size = col_integer(), regularization = col_integer())
)
# non-predictor columns
columns_nonpredictor <- c("Station_name" , "NO2" , "Type_of_zone" , "Type_of_station" ,
"Altitude" , "Canton_ID" , "Canton_name" , "X" , "Y" ,
"CV" , "spatial_CV" , "date")
# //////////////////////////////////////////////////////////////////////////
# naming the model
# //////////////////////////////////////////////////////////////////////////
model_name <- "Neural network"
model_abbr <- "NN"
SAT_product <- c("OMI" , "TROPOMI")[1]
# subset data: satellite-product
if(SAT_product == "OMI"){
data_daily <- data_daily_raw %>%
# OMI
select(-TROPOMI_NO2, -ends_with("12H")) %>%
# drop NA
drop_na() %>%
# date as DOY (numeric)
mutate(DOY = yday(date))
}else if(SAT_product == "TROPOMI") {
data_daily <- data_daily_raw %>%
# TROPOMI
select(-OMI_NO2, -ends_with("15H")) %>%
# drop NA
drop_na() %>%
# date as DOY (numeric)
mutate(DOY = yday(date))
}
# //////////////////////////////////////////////////////////////////////////
# model development
# //////////////////////////////////////////////////////////////////////////
# =====================================
# modularized NN model definition
# =====================================
source("2_scripts/utils_define-NN.R")
# =====================================
# feature selection
# =====================================
# single-hidden-layer neural network for screening
set.seed(20210803)
NN_screen <- nnet(
x = data_daily %>%
drop_na() %>%
select(-all_of(columns_nonpredictor)) %>%
# random-value variables
mutate(R1 = runif(n()) ,
R2 = runif(n()) ,
R3 = runif(n()) ) ,
y = data_daily %>%
drop_na() %>%
select(NO2) ,
size = 50 , linout = TRUE , MaxNWts = 1e5
)
# variables importance using Garson's algorithm
NN_screen_importance <- NeuralNetTools::garson(NN_screen , bar_plot = FALSE) %>%
tibble(variables = row.names(.))
screen_plot <- NN_screen_importance %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)])) %>%
# random
mutate(class = ifelse(str_detect(variables , "R[123]") , "Random" , "Predictor variables")) %>%
# visualization
ggplot(aes(x = variables , y = rel_imp , fill = class)) +
geom_bar(stat = "identity") +
coord_flip() +
scale_fill_lancet() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Screening of relevant predictor variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
screen_plot
# =====================================
# visualization
# =====================================
out_dirpath_plots <- sprintf("3_results/output-graph/model_daily/%s" , model_abbr)
save_plot(
sprintf("%s/importance-screening_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product) ,
plot = screen_plot ,
base_width = 5 , base_height = 8
)
NN_screen_importance %>%
filter(variables %in% included_var_garson) %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)])) %>%
# visualization
ggplot(aes(x = variables , y = rel_imp)) +
geom_bar(stat = "identity") +
coord_flip() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Included variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
# variable selection
included_var_garson <- NN_screen_importance %>%
filter(rel_imp > NN_screen_importance %>%
filter(str_detect(variables , "R[123]")) %>%
# the max importance of the random-value variables
summarize(rel_imp = max(rel_imp)) %>%
unlist) %>%
select(variables) %>%
filter(!str_detect(variables , "R[123]")) %>%
unlist %>% unname
# =====================================
# hyperparameters
# =====================================
hyperparm_vector <- hyper_evaluation %>%
arrange(MAE_CV) %>%
dplyr::slice(9) %>%
select(-contains("_training") , -contains("_CV")) %>%
unlist
hyperparm_vector
hyper_evaluation %>%
arrange(MAE_CV) %>%
dplyr::slice(9)
save_plot(
sprintf("%s/importance-screening_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product) ,
plot = screen_plot ,
base_width = 5 , base_height = 8
)
NN_screen_importance %>%
filter(variables %in% included_var_garson) %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)])) %>%
# visualization
ggplot(aes(x = variables , y = rel_imp)) +
geom_bar(stat = "identity") +
coord_flip() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Included variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
save_plot(
sprintf("%s/importance-included_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product) ,
plot = last_plot() ,
base_width = 5 , base_height = 6
)
SAT_product <- c("OMI" , "TROPOMI")[2]
# subset data: satellite-product
if(SAT_product == "OMI"){
data_daily <- data_daily_raw %>%
# OMI
select(-TROPOMI_NO2, -ends_with("12H")) %>%
# drop NA
drop_na() %>%
# date as DOY (numeric)
mutate(DOY = yday(date))
}else if(SAT_product == "TROPOMI") {
data_daily <- data_daily_raw %>%
# TROPOMI
select(-OMI_NO2, -ends_with("15H")) %>%
# drop NA
drop_na() %>%
# date as DOY (numeric)
mutate(DOY = yday(date))
}
# =====================================
# feature selection
# =====================================
# single-hidden-layer neural network for screening
set.seed(20210803)
NN_screen <- nnet(
x = data_daily %>%
drop_na() %>%
select(-all_of(columns_nonpredictor)) %>%
# random-value variables
mutate(R1 = runif(n()) ,
R2 = runif(n()) ,
R3 = runif(n()) ) ,
y = data_daily %>%
drop_na() %>%
select(NO2) ,
size = 50 , linout = TRUE , MaxNWts = 1e5
)
# variables importance using Garson's algorithm
NN_screen_importance <- NeuralNetTools::garson(NN_screen , bar_plot = FALSE) %>%
tibble(variables = row.names(.))
screen_plot <- NN_screen_importance %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)])) %>%
# random
mutate(class = ifelse(str_detect(variables , "R[123]") , "Random" , "Predictor variables")) %>%
# visualization
ggplot(aes(x = variables , y = rel_imp , fill = class)) +
geom_bar(stat = "identity") +
coord_flip() +
scale_fill_lancet() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Screening of relevant predictor variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
screen_plot
# variable selection
included_var_garson <- NN_screen_importance %>%
filter(rel_imp > NN_screen_importance %>%
filter(str_detect(variables , "R[123]")) %>%
# the max importance of the random-value variables
summarize(rel_imp = max(rel_imp)) %>%
unlist) %>%
select(variables) %>%
filter(!str_detect(variables , "R[123]")) %>%
unlist %>% unname
save_plot(
sprintf("%s/importance-screening_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product) ,
plot = screen_plot ,
base_width = 5 , base_height = 8
)
NN_screen_importance %>%
filter(variables %in% included_var_garson) %>%
# re-order for visualization
mutate(variables = factor(variables , levels = variables[order(rel_imp)])) %>%
# visualization
ggplot(aes(x = variables , y = rel_imp)) +
geom_bar(stat = "identity") +
coord_flip() +
labs(x = "Variables" , y = "Variable importance" ,
title = "Included variables" ,
subtitle = "Relative importance of input variables in neural networks \nusing Garson's algorithm") +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
save_plot(
sprintf("%s/importance-included_%s_%s.png" , out_dirpath_plots , model_abbr , SAT_product) ,
plot = last_plot() ,
base_width = 5 , base_height = 6
)
# DNN hyperparameters
hyper_evaluation <- read_csv(
"3_results/output-data/model_monthly/NN_grid-search/hyper_evaluation.csv",
col_types = cols(layers = col_integer(),
neurons = col_integer(), epochs = col_integer(),
batch.size = col_integer(), regularization = col_integer())
)
# =====================================
# hyperparameters
# =====================================
hyperparm_vector <- hyper_evaluation %>%
arrange(MAE_CV) %>%
dplyr::slice(1) %>%
select(-contains("_training") , -contains("_CV")) %>%
unlist
hyperparm_vector
# DNN hyperparameters
# of the MONTHLY model
hyper_evaluation <- read_csv(
"3_results/output-data/model_monthly/NN_grid-search/hyper_evaluation.csv",
col_types = cols(layers = col_integer(),
neurons = col_integer(), epochs = col_integer(),
batch.size = col_integer(), regularization = col_integer())
)
# =====================================
# hyperparameters
# =====================================
hyperparm_vector <- hyper_evaluation %>%
arrange(MAE_CV) %>%
dplyr::slice(9) %>%
select(-contains("_training") , -contains("_CV")) %>%
unlist
hyperparm_vector
# random forest hyperparameters
hyper_grid <- read_csv("3_results/output-data/model_annual/RF_grid-search/hyper_evaluation.csv")
hyperparm_final <- hyper_grid %>%
arrange(-CV_R2) %>%
slice(2) %>%
as.list()
hyperparm_final
hyper_grid %>%
arrange(-CV_R2) %>%
slice(2)
hyper_grid %>%
arrange(-CV_R2)
# random forest hyperparameters
hyper_grid <- read_csv("3_results/output-data/model_daily/RF_grid-search/hyper_evaluation.csv")
hyperparm_final <- hyper_grid %>%
arrange(-CV_R2) %>%
slice(1) %>%
as.list()
hyperparm_final
# random forest hyperparameters
hyper_grid <- read_csv("3_results/output-data/model_monthly/RF_grid-search/hyper_evaluation.csv")
hyperparm_final <- hyper_grid %>%
arrange(-CV_R2) %>%
slice(3) %>%
as.list()
hyperparm_final
# //////////////////////////////////////////////////////////////////////////
# final model
# //////////////////////////////////////////////////////////////////////////
# =====================================
# hyperparameters from grid search
# =====================================
hyper_grid <- read_csv("3_results/output-data/model_annual/GBM_grid-search/hyper_evaluation.csv")
hyperparm_final <- hyper_grid %>%
arrange(-CV_R2) %>%
dplyr::slice(1) %>%
select(eta, max_depth, min_child_weight, subsample, colsample_bytree) %>%
as.list()
hyperparm_final
# //////////////////////////////////////////////////////////////////////////
# final model
# //////////////////////////////////////////////////////////////////////////
# =====================================
# hyperparameters from grid search
# =====================================
hyper_grid <- read_csv("3_results/output-data/model_monthly/GBM_grid-search/hyper_evaluation.csv")
hyperparm_final <- hyper_grid %>%
arrange(-CV_R2) %>%
dplyr::slice(1) %>%
select(eta, max_depth, min_child_weight, subsample, colsample_bytree) %>%
as.list()
hyperparm_final
# //////////////////////////////////////////////////////////////////////////
# final model
# //////////////////////////////////////////////////////////////////////////
# =====================================
# hyperparameters from grid search
# =====================================
hyper_grid <- read_csv("3_results/output-data/model_daily/GBM_grid-search/hyper_evaluation_full.csv")
hyperparm_final <- hyper_grid %>%
arrange(-CV_R2) %>%
dplyr::slice(1) %>%
select(eta, max_depth, min_child_weight, subsample, colsample_bytree) %>%
as.list()
hyperparm_final
?xgboost
?xgboost::xgboost
citation("keras")
citation("lme4")

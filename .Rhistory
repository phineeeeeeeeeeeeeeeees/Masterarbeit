as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
# define model
set_random_seed(1010) # reproducibility for Keras
NN_define(hyper_grid_row , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = hyper_grid_row["epochs"] ,
batch_size = hyper_grid_row["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
# prediction
prediction_training <- training.data %>%
select(month , Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(NN , predictor_train)[,1])
# # clean environment
# rm(training.data , predictor_train , response_train , NN)
# =====================================
# cross validation
# =====================================
for(k in as.factor(1:k_fold)){
# data preparation: partition
training.data <- data_monthly %>%
filter(CV != k) %>%
drop_na()
testing.data <- data_monthly %>%
filter(CV == k) %>%
drop_na()
# data preparation: make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(all_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
predictor_test <- testing.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(all_of(included_var)) %>%
as.matrix()
response_test <- testing.data %>%
select(NO2) %>%
as.matrix()
# define model
set_random_seed(1010) # reproducibility for Keras
NN_define(hyper_grid_row , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = hyper_grid_row["epochs"] ,
batch_size = hyper_grid_row["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
# prediction
prediction_test <- testing.data %>%
select(month , Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(NN , predictor_test)[,1])
# prediction data.frame
if(as.character(k) == "1"){
prediction_CV <- prediction_test # <-
}else{ # append
prediction_CV <- bind_rows(prediction_CV , prediction_test)
}
# clean environment
rm(k , training.data , testing.data ,
predictor_train , predictor_test , response_train , response_test ,
prediction_test)
}
# =====================================
# evaluate
# =====================================
hyper_evaluation_i <- hyper_grid_row %>%
as.list() %>% as_tibble() %>%
bind_cols(
prediction_training %>%
full_join(prediction_CV ,
by = c("Station_name" , "NO2" , "Type_of_station" , "CV" , "month") ,
suffix = c("" , "_CV")) %>%
# calculate the indices from the observed and predicted values
summarize(MSE_training = mse(NO2 , predicted) ,
MSE_CV = mse(NO2 , predicted_CV) ,
MAE_training = mae(NO2 , predicted) ,
MAE_CV = mae(NO2 , predicted_CV) ,
R2_training = cor(NO2 , predicted)^2 ,
R2_CV = cor(NO2 , predicted_CV)^2 )
)
# function return
return(hyper_evaluation_i)
}
cl <- makeCluster(cpu.cores)
# clusterExport
# 在使用預設PSOCK cluster時，若想要讓所有的節點可以使用預先設定好的全域變數，必須以clusterExport將變數傳遞至所有節點，之後才能在各個節點中使用
clusterExport(
cl = cl ,
varlist = c("data_monthly" , "k_fold" , "included_var_all" , "included_var_garson" , "NN_define")
)
# grid search function for "apply"
search_hyper_grid <- function(hyper_grid_row){
# hyper_grid_row is the hyperparameter (one row of "hyper_grid")
# load packages for the clusters
library(dplyr) ; library(tidyr) ;
library(keras) ; library(tensorflow)
library(Metrics)
# =====================================
# feature selection
# =====================================
if(is.na(hyper_grid_row["garson_selection"])){
included_var <- included_var_all
}else if(hyper_grid_row["garson_selection"] == 1){
included_var <- included_var_garson
}
# =====================================
# full training set
# =====================================
training.data <- data_monthly %>%
drop_na()
# make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(one_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
# define model
set_random_seed(1010) # reproducibility for Keras
NN_define(hyper_grid_row , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = hyper_grid_row["epochs"] ,
batch_size = hyper_grid_row["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
# prediction
prediction_training <- training.data %>%
select(month , Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(NN , predictor_train)[,1])
# # clean environment
# rm(training.data , predictor_train , response_train , NN)
# =====================================
# cross validation
# =====================================
for(k in as.factor(1:k_fold)){
# data preparation: partition
training.data <- data_monthly %>%
filter(CV != k) %>%
drop_na()
testing.data <- data_monthly %>%
filter(CV == k) %>%
drop_na()
# data preparation: make matrix
predictor_train <- training.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(all_of(included_var)) %>%
as.matrix()
response_train <- training.data %>%
select(NO2) %>%
as.matrix()
predictor_test <- testing.data %>%
# select(-all_of(columns_nonpredictor)) %>%
select(all_of(included_var)) %>%
as.matrix()
response_test <- testing.data %>%
select(NO2) %>%
as.matrix()
# define model
set_random_seed(1010) # reproducibility for Keras
NN_define(hyper_grid_row , n_var = ncol(predictor_train))
# train model
NN %>%
fit(predictor_train , response_train ,
epoch = hyper_grid_row["epochs"] ,
batch_size = hyper_grid_row["batch.size"] ,
validation_split = 0.2 ,
verbose = FALSE)
# prediction
prediction_test <- testing.data %>%
select(month , Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(NN , predictor_test)[,1])
# prediction data.frame
if(as.character(k) == "1"){
prediction_CV <- prediction_test # <-
}else{ # append
prediction_CV <- bind_rows(prediction_CV , prediction_test)
}
# clean environment
rm(k , training.data , testing.data ,
predictor_train , predictor_test , response_train , response_test ,
prediction_test)
}
# =====================================
# evaluate
# =====================================
hyper_evaluation_i <- hyper_grid_row %>%
as.list() %>% as_tibble() %>%
bind_cols(
prediction_training %>%
full_join(prediction_CV ,
by = c("Station_name" , "NO2" , "Type_of_station" , "CV" , "month") ,
suffix = c("" , "_CV")) %>%
# calculate the indices from the observed and predicted values
summarize(MSE_training = mse(NO2 , predicted) ,
MSE_CV = mse(NO2 , predicted_CV) ,
MAE_training = mae(NO2 , predicted) ,
MAE_CV = mae(NO2 , predicted_CV) ,
R2_training = cor(NO2 , predicted)^2 ,
R2_CV = cor(NO2 , predicted_CV)^2 )
)
# function return
return(hyper_evaluation_i)
}
# grid search
hyper_evaluation <- hyper_grid %>%
pbapply(MARGIN = 1 , FUN = search_hyper_grid , cl = cl) %>%
bind_rows()
# turn off cluster
stopCluster(cl)
# =====================================
# export grid search results
# =====================================
out_dirpath_grid_search <- "3_results/output-data/model_monthly/NN_grid-search"
if(!dir.exists(out_dirpath_grid_search)) dir.create(out_dirpath_grid_search)
hyper_evaluation %>%
write_csv(sprintf("%s/hyper_evaluation.csv" , out_dirpath_grid_search))
cowplot::save_plot(
sprintf("%s/garson_screening.png" , out_dirpath_grid_search) ,
plot = screen_plot ,
base_width = 6 , base_height = 10
)
hyper_evaluation %>%
arrange(-R2_CV) %>% View
source('~/Masterarbeit/2_scripts/monthly_NN.R')
NN_indices
hyperparm_vector
hyper_evaluation %>%
arrange(MAE_CV)
source('~/Masterarbeit/2_scripts/monthly_NN.R')
NN_indices
source('~/Masterarbeit/2_scripts/monthly_NN.R')
NN_indices
library(readr)
library(sf)
library(dplyr) ; library(tidyr)
library(ggplot2) ; library(ggsci) ; library(ggthemes)
library(lubridate) ; library(stringr)
library(spdep)
library(Metrics)
library(ranger)
# =====================================
# load datasets
# =====================================
# training data
data_daily_raw <- read_csv("1_data/processed/cleaned/extracted/daily_scaled.csv")
# cross validation
{
in_filepath_CV <- list.files("1_data/processed/cleaned/extracted/" , "CV.shp$" , full.names = TRUE)
sites_CV <- st_read(in_filepath_CV) %>%
rename(Station_name = Station)
k_fold <- in_filepath_CV %>%
str_extract("\\d+-fold") %>% str_extract("\\d+") %>%
as.integer()
}
# implement the CV design in the training data
data_daily_raw <- data_daily_raw %>%
inner_join(sites_CV , by = "Station_name") %>%
select(-geometry)
# non-predictor columns
columns_nonpredictor <- c("Station_name" , "Type_of_zone" , "Type_of_station" ,
"Altitude" , "Canton_ID" , "Canton_name" , "X" , "Y" ,
"CV" , "spatial_CV")
# //////////////////////////////////////////////////////////////////////////
# naming the model
# //////////////////////////////////////////////////////////////////////////
SAT_product <- "TROPOMI"
# subset data: satellite-product
if(SAT_product == "OMI"){
# for the OMI model: exclude TROPOMI and meteorological variables at 12H
data_daily <- data_daily_raw %>%
select(-TROPOMI_NO2 , -ends_with("_12H"))
}else if(SAT_product == "TROPOMI"){
# for the TROPOMI model: exclude OMI and meteorological variables at 15H
data_daily <- data_daily_raw %>%
select(-OMI_NO2 , -ends_with("_15H"))
}
# =====================================
# screening of important variables
# =====================================
set.seed(1010)
rf_screen <- ranger(NO2 ~ . ,
data = data_daily %>%
# drop non-predictor columns
select(-all_of(columns_nonpredictor)) %>%
drop_na() %>%
# random-value variables
mutate(R1 = runif(n()) ,
R2 = runif(n()) ,
R3 = runif(n()) ) ,
importance = "impurity" ,
keep.inbag = TRUE ,
num.trees = 3000 ,
mtry = 30 )
rf_screen_importance <- rf_screen$variable.importance %>%
sort(decreasing = TRUE) %>%
as.list() %>%
as_tibble() %>%
pivot_longer(cols = everything() , names_to = "variable" , values_to = "importance")
# visualization
rf_screen_importance %>%
mutate(class = ifelse(str_detect(variable , "R[123]") , "Random" , "Predictor variables")) %>%
# reorder for visualization
mutate(variable = factor(variable , levels = variable[order(importance)])) %>%
# visualization
ggplot(aes(x = variable , y = importance , fill = class)) +
geom_bar(stat = "identity") +
coord_flip() +
scale_fill_lancet() +
labs(x = "Variables" , y = "Variable importance" , fill = "" ,
title = "Screening of relevant predictor variables" ,
subtitle = sprintf("The variable importance of the random forest model (%s)" , SAT_product)) +
theme_bw() +
theme(axis.text.y = element_text(size = 4) , legend.position = "bottom")
# exclude not-important variables
included_var <- rf_screen_importance %>%
filter(importance > rf_screen_importance %>%
filter(str_detect(variable , "R[123]")) %>%
# the max importance of the random-value variables
summarize(importance = max(importance)) %>%
unlist)
formula_rf_final <- included_var %>%
select(variable) %>%
unlist %>% unname() %>%
paste(collapse = " + ") %>%
sprintf("NO2 ~ %s" , .)
# //////////////////////////////////////////////////////////////////////////
# grid search for best model hyperparameters
# //////////////////////////////////////////////////////////////////////////
# =====================================
# create hyperparameter grid
# =====================================
# create hyperparameter grid
hyper_grid <- expand.grid(
# Number of variables to possibly split at in each node.
# Default is the (rounded down) square root of the number variables
mtry = c(3,5,8,10,15) ,
# Number of trees.
N.trees = c(50,100,150,250,300,500,1000,1500,2000,3000) ,
# a place to dump results
OOB_MSE = NA,
OOB_R2 = NA ,
CV_R2 = NA
)
# =====================================
# grid search
# =====================================
pb <- txtProgressBar(min = 1 , max = nrow(hyper_grid) , style = 3 )
for(i in 1:nrow(hyper_grid)) {
# reproducibility
set.seed(123)
# train model
rf_grid <- ranger(formula_rf_final ,
data = data_daily %>%
drop_na() ,
importance = "impurity" ,
keep.inbag = TRUE ,
num.trees = hyper_grid$N.trees[i] ,
mtry = hyper_grid$mtry[i] )
# conventional CV
for(k in as.factor(1:k_fold)){
# partition
training.data <- data_daily %>%
filter(CV != k)
testing.data <- data_daily %>%
filter(CV == k)
# train model
set.seed(123)
rf_grid_cv <- ranger(
formula = formula_rf_final  ,  # <-
data = training.data %>%
drop_na() ,
importance = "impurity" ,
keep.inbag = TRUE ,
num.trees = hyper_grid$N.trees[i] ,
mtry = hyper_grid$mtry[i]
)
# prediction
prediction_test <- testing.data %>%
select(Station_name , NO2 , Type_of_station , CV) %>%
# prediction
mutate(predicted = predict(rf_grid_cv , data = testing.data)$predictions)
# prediction data.frame
if(as.character(k) == "1"){
rf_grid_prediction_CV <- prediction_test # <-
}else{ # append
rf_grid_prediction_CV <- bind_rows(rf_grid_prediction_CV , prediction_test) # <-
}
# clean environment
rm(training.data , testing.data , rf_grid_cv , prediction_test , k)
}
# evaluation (add to hyper_grid data.frame)
# OOB-RMSE
hyper_grid$OOB_MSE[i] <- rf_grid$prediction.error
# OOB-R2
hyper_grid$OOB_R2[i] <- rf_grid$r.squared
# CV-R2
hyper_grid$CV_R2[i] <- cor(rf_grid_prediction_CV$NO2 , rf_grid_prediction_CV$predicted ,
use = "na.or.complete")^2
# progress bar
setTxtProgressBar(pb,i)
# clean environment
rm(rf_grid_prediction_CV , rf_grid)
}
rm(pb,i)
# =====================================
# visualization: best hyperparameter
# =====================================
hyper_grid %>%
pivot_longer(cols = ends_with("R2") ,
names_to = c("type" , "indices") , names_sep = "_" ,
values_to = "R2") %>%
mutate(mtry = factor(mtry) ,
type = factor(type , levels = c("OOB" , "CV"))) %>%
# visualization
ggplot(aes(x = N.trees , y = R2 , color = mtry)) +
geom_line() +
geom_point() +
facet_grid(type~. , scales = "free_y") +
scale_color_manual(values = RColorBrewer::brewer.pal(length(unique(hyper_grid$mtry)),"Spectral")) +
labs(x = "Number of trees" , y = expression(R^2) ,
title = "Grid search of random forest hyperparameters") +
theme_bw()
# =====================================
# export grid search results
# =====================================
out_dirpath_hypergrid <- "3_results/output-data/model_daily/RF_grid-search"
if(!dir.exists(out_dirpath_hypergrid)) dir.create(out_dirpath_hypergrid , recursive = TRUE)
hyper_grid %>%
write_csv(sprintf("%s/hyper_evaluation.csv" , out_dirpath_hypergrid))
# =====================================
# visualization: best hyperparameter
# =====================================
hyper_grid %>%
pivot_longer(cols = ends_with("R2") ,
names_to = c("type" , "indices") , names_sep = "_" ,
values_to = "R2") %>%
mutate(mtry = factor(mtry) ,
type = factor(type , levels = c("OOB" , "CV"))) %>%
# visualization
ggplot(aes(x = N.trees , y = R2 , color = mtry)) +
geom_line() +
geom_point() +
facet_grid(type~. , scales = "free_y") +
scale_color_manual(values = RColorBrewer::brewer.pal(length(unique(hyper_grid$mtry)),"Spectral")) +
labs(x = "Number of trees" , y = expression(R^2) ,
title = "Grid search of random forest hyperparameters") +
theme_bw()
ggsave(sprintf("%s/hyper_evaluation.png" , out_dirpath_hypergrid) , width = 5 , height = 5)
source("2_scripts/utils_model-eval.R")
# =====================================
# load datasets
# =====================================
# training data
data_daily_raw <- read_csv("1_data/processed/cleaned/extracted/daily_scaled.csv")
# cross validation
{
in_filepath_CV <- list.files("1_data/processed/cleaned/extracted/" , "CV.shp$" , full.names = TRUE)
sites_CV <- st_read(in_filepath_CV) %>%
rename(Station_name = Station)
k_fold <- in_filepath_CV %>%
str_extract("\\d+-fold") %>% str_extract("\\d+") %>%
as.integer()
}
# implement the CV design in the training data
data_daily_raw <- data_daily_raw %>%
inner_join(sites_CV , by = "Station_name") %>%
select(-geometry)
# non-predictor columns
columns_nonpredictor <- c("Station_name" , "Type_of_zone" , "Type_of_station" ,
"Altitude" , "Canton_ID" , "Canton_name" , "X" , "Y" ,
"CV" , "spatial_CV")
# //////////////////////////////////////////////////////////////////////////
# naming the model
# //////////////////////////////////////////////////////////////////////////
model_name <- "Random forest"
model_abbr <- "RF"
SAT_product <- c("OMI" , "TROPOMI")[1]
# random forest hyperparameters
hyper_grid <- read_csv("3_results/output-data/model_daily/RF_grid-search/hyper_evaluation.csv")
hyperparm_final <- hyper_grid %>%
arrange(-CV_R2) %>%
slice(1) %>%
as.list()
hyperparm_final
# =====================================
# subset data: satellite-product
# =====================================
if(SAT_product == "OMI"){
# for the OMI model: exclude TROPOMI and meteorological variables at 12H
data_daily <- data_daily_raw %>%
select(-TROPOMI_NO2 , -ends_with("_12H"))
}else if(SAT_product == "TROPOMI"){
# for the TROPOMI model: exclude OMI and meteorological variables at 15H
data_daily <- data_daily_raw %>%
select(-OMI_NO2 , -ends_with("_15H"))
}
